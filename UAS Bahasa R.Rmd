---
title: "UAS Bahasa R"
author: "36220014-Wisely Yestin & 36220017 - Denis Winata DS"
---

#install packages
install.packages('dplyr')
install.packages('corrplot')
install.packages('nortest')
install.packages('moments')
install.packages('outliers')
install.packages('GGally')
install.packages('ggplot2')
install.packages('Metrics')
install.packages('caret')
install.packages('boot')
install.packages('performanceEstimation')
install.packages('pROC')
install.packages('psych')
install.packages('randomForest')
install.packages('rpart')
install.packages('e1071')
install.packages('gbm')
install.packages('class')
install.packages('nnet')
install.packages('xgboost')
install.packages('adabag')
install.packages('shiny')
install.packages('shinydashboard')
install.packages('shinyjs')

#import library
```{r}
library(dplyr)
library(corrplot)
library(nortest)
library(moments)
library(outliers)
library(GGally)
library(ggplot2)
library(Metrics)
library(caret)
library(boot)
library(performanceEstimation)
library(pROC)
library(psych)
```
#Load Dataset
```{r}
profiling=read.csv('profiling.csv', sep=';')
admisi=read.csv('admisi.csv', sep=';')

str(profiling)
str(admisi)

#View(profiling)
#View(admisi)
```
#eksplorasi data
```{r}
#cek apakah ada mising value?
anyNA(profiling)
anyNA(admisi)
```
#cek jumlah mising value
```{r}
missing_values_profiling = sapply(profiling, function(x) sum(is.na(x)))
missing_values_profiling
missing_values_admisi = sapply(admisi, function(x) sum(is.na(x)))
missing_values_admisi
```
#cek duplikat data
```{r}
anyDuplicated(profiling)
anyDuplicated(admisi)
#eksplor dataset
describe(admisi)
describe(profiling)
```
#data preprocessing

```{r}
profiling$IPK=gsub(",", ".", profiling$IPK)
profiling$IPK=as.numeric(profiling$IPK)
profiling$USIA=as.numeric(profiling$USIA)
profiling$Ranking_Uni_Asal=as.numeric(profiling$Ranking_Uni_Asal)

admisi$GRE=as.numeric(admisi$GRE)
admisi$TOEFL=as.numeric(admisi$TOEFL)
admisi$MOT_LETTER=gsub(",", ".", admisi$MOT_LETTER)
admisi$MOT_LETTER=as.numeric(admisi$MOT_LETTER)
admisi$REKOM_LETTER=gsub(",", ".", admisi$REKOM_LETTER)
admisi$REKOM_LETTER=as.numeric(admisi$REKOM_LETTER)

str(profiling)
str(admisi)
```

#Merge kedua dataset
```{r}
datauas=merge(profiling,admisi, by='ID')
datauas
str(datauas)
```
# Cek variasi keunikan data
```{r}
unique(datauas$JENIS_KEL)
unique(datauas$USIA)
unique(datauas$Ranking_Uni_Asal)#ada mising value
unique(datauas$RISET)#ada mising value tpi terisi kosong
unique(datauas$LULUS)#ada mising value
```

```{r}
mising_value_datauas=sapply(datauas, function(x) sum(is.na(x)))
mising_value_datauas
```

#handling missing value
```{r}
# Cek modus pada kolom missing value
modus_ranking = names(sort(table(datauas$Ranking_Uni_Asal), decreasing = TRUE)[1])
modus_ranking
modus_riset = names(sort(table(datauas$RISET), decreasing = TRUE)[1])
modus_riset
modus_lulus = names(sort(table(datauas$LULUS), decreasing = TRUE)[1])
modus_lulus

# Mengganti nilai NA dengan modus
datauas$LULUS[is.na(datauas$LULUS)] = modus_lulus
datauas$LULUS=as.factor(datauas$LULUS)
datauas$LULUS = factor(datauas$LULUS, levels = c(1, 0), labels = c('Lulus', 'Tidak Lulus'))
datauas$Ranking_Uni_Asal[is.na(datauas$Ranking_Uni_Asal)] = modus_ranking
datauas$Ranking_Uni_Asal=as.numeric(datauas$Ranking_Uni_Asal)
datauas$JENIS_KEL = as.factor(datauas$JENIS_KEL)

##mengisi kolom riset yg kosong namun tdk dianggep NA
# Membuat vektor dengan pilihan nilai "Ya" dan "Tidak"
choices = c("Ya", "Tidak")

# Mengidentifikasi indeks data yang kosong pada kolom "RISET"
kosong_index = which(datauas$RISET == "")

# Mendapatkan jumlah data yang kosong
jumlah_kosong = length(kosong_index)

# Menghasilkan nilai acak dan menggantikan nilai kosong
set.seed(123) 
datauas$RISET[kosong_index] <- sample(choices, jumlah_kosong, replace = TRUE)
datauas$RISET=as.factor(datauas$RISET)

# Mengisi nilai kosong dengan random
#datauas$RISET[is.na(datauas$RISET)] = sample(datauas$RISET[!is.na(datauas$RISET)], #sum(is.na(datauas$RISET)), replace = TRUE)

# Periksa apakah masih terdapat missing value
sum(is.na(datauas))
```

```{r}
summary(datauas)
describe(datauas)
```

# Handling Outlier
```{r}
#cek outlier dengan boxplot
boxplot(datauas$USIA)
boxplot(datauas$Ranking_Uni_Asal)
boxplot(datauas$IPK)#ad 2 outlier diatas
boxplot(datauas$GRE)
boxplot(datauas$TOEFL)
boxplot(datauas$MOT_LETTER)
boxplot(datauas$REKOM_LETTER)#ada 2 outlier dibawah
```

```{r}
# cek dan hapus outlier
# Loop untuk menampilkan boxplot satu per satu untuk variabel numerik
for (col in names(datauas)) {
  if (is.numeric(datauas[[col]])) {
    boxplot(datauas[[col]], main = col)
  }
}

# Menghapus Outliers pada IPK dan rekom letter
IQR_ipk = IQR(datauas$IPK)
up_outlier_ipk = quantile(datauas$IPK, 0.75) + 1.5 * IQR_ipk 

IQR_rekom = IQR(datauas$REKOM_LETTER)
low_outlier_rekom = quantile(datauas$REKOM_LETTER, 0.25) - 1.5 * IQR_rekom

datauas = subset(datauas, datauas$IPK <= up_outlier_ipk & datauas$REKOM_LETTER >= low_outlier_rekom)

# Mengecek apakah masih terdapat outliers
for (col in names(datauas)) {
  if (is.numeric(datauas[[col]])) {
    boxplot(datauas[[col]], main = col)
  }
}
```

#Normalisasi
```{r}
#cek normalisasi dengan test
#P value> 0,05 bagus
lillie.test(datauas$IPK)
lillie.test(datauas$Ranking_Uni_Asal)
lillie.test(datauas$GRE)
lillie.test(datauas$TOEFL)
lillie.test(datauas$MOT_LETTER)
lillie.test(datauas$REKOM_LETTER)

pearson.test(datauas$IPK)
pearson.test(datauas$Ranking_Uni_Asal)
pearson.test(datauas$GRE)
pearson.test(datauas$TOEFL)
pearson.test(datauas$MOT_LETTER)
pearson.test(datauas$REKOM_LETTER)

```

```{r}
#cek normalisasi dengan histogram
hist(datauas$USIA)
hist(datauas$Ranking_Uni_Asal)
hist(datauas$IPK)
hist(datauas$GRE)
hist(datauas$TOEFL)
hist(datauas$MOT_LETTER)
hist(datauas$REKOM_LETTER)
```

#Korelasi
```{r}
# Menghitung matriks korelasi antara kolom numerik
cor_matrix = cor(datauas[, sapply(datauas, is.numeric)])

# Plotting heatmap dengan ggplot2
ggplot(data = reshape2::melt(cor_matrix), aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, 
                       limit = c(-1,1), space = "Lab", name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
#feature usia dan id kurang penting
```

#Feature selection
```{r}
# Menentukan kontrol untuk model pembelajaran
control = trainControl(method="repeatedcv", number=15, repeats=5)

# Membuat model menggunakan train()
model = train(LULUS ~ ., data = datauas[, setdiff(names(datauas), "NAMA")], method = "lvq", preProcess = "scale", trControl = control)

# Menilai fitur yang penting
feature_selection = varImp(model, scale=FALSE)

# Plotting grafik tingkat pentingnya fitur
plot(feature_selection)
#feature usia,nama,id kurang penting
```

##modeling
```{r}
# Install dan load library yang dibutuhkan
#install.packages(c("randomForest", "rpart", "e1071", "gbm", "class", "nnet", "xgboost", "adabag"))
library(randomForest)
library(rpart)
library(e1071)
library(gbm)
library(class)
library(nnet)
library(xgboost)
library(adabag)

# Feature selection
predictors = c("RISET", "REKOM_LETTER", "MOT_LETTER", "Ranking_Uni_Asal", "GRE", "TOEFL", "IPK")

# Split train dan testing data
set.seed(123)  # Set seed for reproducibility
split_ratio <- 0.8 # 80% training, 20% testing
num_rows <- nrow(datauas)
train_indices <- sample(1:num_rows, size = round(split_ratio * num_rows))
train_data <- datauas[train_indices, ]
test_data <- datauas[-train_indices, ]
```

# Model Random Forest
```{r}
# Model Random Forest
rf_model = randomForest(factor(LULUS) ~ ., data = train_data[, c("LULUS", predictors)], ntree = 500, importance = TRUE)

# Model Prediction 
predictions_rf = predict(rf_model, newdata = test_data)

# Evaluate the model
conf_matrix = confusionMatrix(predictions_rf, test_data$LULUS)
accuracy_rf = conf_matrix$overall["Accuracy"]
precision_rf = conf_matrix$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Accuracy:", accuracy_rf))
print(paste("Precision:", precision_rf))
```

#Cross Validation Random Forest
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated Random Forest model
rf_model_cv = train(factor(LULUS) ~ .,
                      data = train_data[, c("LULUS", predictors)],
                      method = "rf",
                      trControl = trainControl(method = "cv", number = cv_folds),
                      ntree = 500,
                      importance = TRUE)

# Print model summary
print(rf_model_cv)
```

# Curve ROC dan AUC Random Forest
```{r}
# Calculate ROC
roc_rf = roc(test_data$LULUS, as.numeric(predictions_rf))

# Display evaluation metrics
print(paste("Random Forest Accuracy:", accuracy_rf))
print(paste("Random Forest Precision:", precision_rf))

# Plot ROC curve for Random Forest
plot(roc_rf, col = "blue", main = "ROC Curve (Random Forest)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_rf = auc(roc_rf)
print(paste("Random Forest AUC:", auc_rf))
```

# Model Decision Tree
```{r}
library(rpart)

# Create and train the Decision Tree model
tree_model = rpart(LULUS ~ ., data = train_data[, c("LULUS", predictors)], method = "class")

# Model Prediction 
predictions_dt = predict(tree_model, newdata = test_data, type = "class")

# Evaluate the model
conf_matrix_dt = confusionMatrix(predictions_dt, test_data$LULUS)
accuracy_dt = conf_matrix_dt$overall["Accuracy"]
precision_dt = conf_matrix_dt$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Decision Tree Accuracy:", accuracy_dt))
print(paste("Decision Tree Precision:", precision_dt))
```

# Cross Validation Decision Tree
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated Decision Tree model
dt_model_cv = train(factor(LULUS) ~ .,
                     data = train_data[, c("LULUS", predictors)],
                     method = "rpart",
                     trControl = trainControl(method = "cv", number = cv_folds, verboseIter = TRUE),
                     tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)))

# Print model summary
print(dt_model_cv)
```

# Curve ROC dan AUC Decision Tree
```{r}
# Calculate ROC
roc_dt = roc(test_data$LULUS, as.numeric(predictions_dt))

# Display evaluation metrics
print(paste("Decision Tree Accuracy:", accuracy_dt))
print(paste("Decision Tree Precision:", precision_dt))

# Plot ROC curve for Decision Tree
plot(roc_dt, col = "blue", main = "ROC Curve (Decision Tree)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_dt = auc(roc_dt)
print(paste("Decision Tree AUC:", auc_dt))
```

# Model SVM
```{r}
# Model SVM
svm_reg_model = svm(LULUS ~ ., data = train_data[, c("LULUS", predictors)])

# Model Prediction 
predictions_svm_reg = predict(svm_reg_model, newdata = test_data)

# Evaluate the model
conf_matrix_svm_reg = confusionMatrix(predictions_svm_reg, test_data$LULUS)
accuracy_svm_reg = conf_matrix_svm_reg$overall["Accuracy"]
precision_svm_reg = conf_matrix_svm_reg$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("SVM Accuracy:", accuracy_svm_reg))
print(paste("SVM Precision:", precision_svm_reg))
```

# Cross Validation SVM
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated SVM model
svm_model_cv = train(factor(LULUS) ~ .,
                      data = train_data[, c("LULUS", predictors)],
                      method = "svmRadial",
                      trControl = trainControl(method = "cv", number = cv_folds),
                      tuneLength = 5)  # Number of values to try for tuning parameter

# Print model summary
print(svm_model_cv)
```

# Curve ROC dan AUC SVM
```{r}
# Calculate ROC
roc_svm_reg = roc(test_data$LULUS, as.numeric(predictions_svm_reg))

# Display evaluation metrics
print(paste("SVM Accuracy:", accuracy_svm_reg))
print(paste("SVM Precision:", precision_svm_reg))

# Plot ROC curve for SVM
plot(roc_svm_reg, col = "blue", main = "ROC Curve (SVM Regresi)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_svm_reg = auc(roc_svm_reg)
print(paste("SVM AUC:", auc_svm_reg))
```

# Model KNN
```{r}
library(class)

# Create and train the KNN model
knn_model = knn(train_data[, c("Ranking_Uni_Asal", "IPK", "GRE", "TOEFL", "MOT_LETTER", "REKOM_LETTER")],
                 test_data[, c("Ranking_Uni_Asal", "IPK", "GRE", "TOEFL", "MOT_LETTER", "REKOM_LETTER")],
                 train_data$LULUS, k = 5)

# Evaluate the model
conf_matrix_knn = confusionMatrix(knn_model, test_data$LULUS)
accuracy_knn = conf_matrix_knn$overall["Accuracy"]
precision_knn = conf_matrix_knn$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("KNN Accuracy:", accuracy_knn))
print(paste("KNN Precision:", precision_knn))
```

# Cross Validation KNN
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated KNN model
knn_model_cv = train(factor(LULUS) ~ .,
                      data = train_data[, c("LULUS", predictors)],
                      method = "knn",
                      trControl = trainControl(method = "cv", number = cv_folds),
                      tuneGrid = data.frame(k = seq(1, 10)))  # Number of neighbors to try

# Print model summary
print(knn_model_cv)
```

# Curve ROC dan AUC KNN
```{r}
# Calculate ROC
roc_knn = roc(test_data$LULUS, as.numeric(knn_model))

# Display evaluation metrics
print(paste("KNN Accuracy:", accuracy_knn))
print(paste("KNN Precision:", precision_knn))

# Plot ROC curve for KNN
plot(roc_knn, col = "blue", main = "ROC Curve (KNN)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_knn = auc(roc_knn)
print(paste("KNN AUC:", auc_knn))
```

# Model Naive Bayes
```{r}
# Model Naive Bayes
library(e1071)
nb_reg_model = naiveBayes(LULUS ~ ., data = train_data[, c("LULUS", predictors)])

# Model Prediction 
predictions_nb_reg = predict(nb_reg_model, newdata = test_data)

# Evaluate the model
conf_matrix_nb_reg = confusionMatrix(predictions_nb_reg, test_data$LULUS)
accuracy_nb_reg = conf_matrix_nb_reg$overall["Accuracy"]
precision_nb_reg = conf_matrix_nb_reg$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Naive Bayes Accuracy:", accuracy_nb_reg))
print(paste("Naive Bayes Precision:", precision_nb_reg))
```

# Cross Validation Naive Bayes
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated Naive Bayes model
nb_model_cv = train(factor(LULUS) ~ .,
                     data = train_data[, c("LULUS", predictors)],
                     method = "nb",
                     trControl = trainControl(method = "cv", number = cv_folds))

# Print model summary
print(nb_model_cv)
```

# Curve ROC dan AUC Naive Bayes
```{r}
# Calculate ROC
roc_nb_reg = roc(test_data$LULUS, as.numeric(predictions_nb_reg))

# Display evaluation metrics
print(paste("Naive Bayes Accuracy:", accuracy_nb_reg))
print(paste("Naive Bayes Precision:", precision_nb_reg))

# Plot ROC curve for Naive Bayes
plot(roc_nb_reg, col = "blue", main = "ROC Curve (Naive Bayes)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_nb_reg = auc(roc_nb_reg)
print(paste("Naive Bayes AUC:", auc_nb_reg))
```

# Merge Curve ROC Every Model
```{r}
library(pROC)

# Plot ROC curves for each model
plot(roc_rf, col = "blue", main = "Merge ROC Curves", lwd = 2, cex.main = 1.5, cex.lab = 1.2, cex.axis = 1.2)
lines(roc_dt, col = "red", lwd = 2)
lines(roc_svm, col = "green", lwd = 2)
lines(roc_knn, col = "purple", lwd = 2)
lines(roc_nb, col = "orange", lwd = 2)

# Add legend
legend("bottomright", legend = c("Random Forest", "Decision Tree", "SVM", "KNN", "Naive Bayes"),
       col = c("blue", "red", "green", "purple", "orange"), lwd = 2)

```

# Visualisasi Perbandingan Hasil Auc Setiap Model
```{r}
# Perbandingan AUC Setiap Model
model_auc <- c(auc(roc_rf), auc(roc_dt), auc(roc_svm), auc(roc_knn), auc(roc_nb))

# Visualisasi dengan bar plot
barplot(model_auc, names.arg = c("Random Forest", "Decision tree", "SVM", "KNN", "Naive Bayes"),
        col = c("blue", "red", "green", "purple", "orange"),
        main = "Perbandingan AUC Setiap Model",
        xlab = "Model", ylab = "AUC", ylim = c(0, 1),
        cex.main = 1, cex.lab = 1, cex.axis = 1)

# Menambahkan nilai AUC di atas batang
text(seq_along(model_auc), model_auc + 0.02, labels = sprintf("%.3f", model_auc),
     cex = 0.8, col = "black", pos = 4)

```

# Visualisasi Perbandingan Akurasi dan Presisi Setiap Model
```{r}
library(ggplot2)

# Define model names and evaluation metrics
model_names = c("Random Forest", "Decision Tree", "SVM", "KNN", "Naive Bayes")
accuracies = c(accuracy_rf, accuracy_dt, accuracy_svm_reg, accuracy_knn, accuracy_nb_reg)
precisions = c(precision_rf, precision_dt, precision_svm_reg, precision_knn, precision_nb_reg)

# Create a data frame for visualization
model_metrics = data.frame(Model = model_names, Accuracy = accuracies, Precision = precisions)

# Melt the data for better visualization with ggplot2
library(reshape2)
model_metrics_melted = melt(model_metrics, id.vars = "Model", variable.name = "Metric", value.name = "Value")

# Create a bar chart with labels on Y-axis
ggplot(model_metrics_melted, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  labs(title = "Comparison of Model Performance",
       y = "Metric Value",
       x = "Model") +
  scale_fill_manual(values = c("Accuracy" = "skyblue", "Precision" = "coral")) +
  theme_minimal() +
  geom_text(aes(label = sprintf("%.2f", Value), y = Value), vjust = -0.5, position = position_dodge(width = 0.9))

```
# Narasi Hasil Evaluasi performa model-model tersebut dengan melakukan evaluasi baik pada data training dan data testing dengan metric precision.
# decision tree= akurasi 95, presisi 96, AUC 52,4
# knn = akurasi 93, presisi 96, AUC 89
# svm= akurasi 97, presisi 96, AUC 81,1
# random forest= akurasi 94, presisi 96, AUC 93,2
# naive bayes= akurasi 96, presisi 90, AUC 96,2

# AUC mengukur area di bawah kurva ROC. Nilai AUC berkisar antara 0 hingga 1, di mana nilai 1 menunjukkan kinerja sempurna dan nilai 0.5 menunjukkan kinerja yang setara dengan pengacakan acak.

# Semakin besar nilai AUC, semakin baik model dapat membedakan antara kelas positif dan negatif. Jadi model dengan AUC tertinggi dianggap sebagai model yang lebih baik dalam membedakan antara kelas positif dan negatif.

# Menurut kami setelah mengevaluasi performa berbagai model, kami berkesimpulan bahwa SVM adalah pilihan terbaik untuk digunakan dalam web Shiny kami. Meskipun Naive Bayes menunjukkan presisi yang baik sebesar 90%, yang memenuhi standar IEDU sebesar 85%, SVM memiliki keunggulan dalam beberapa aspek penting. 
# SVM memiliki akurasi yang sangat tinggi, mencapai 97%, yang membuatnya menjadi model yang dapat diandalkan untuk memprediksi keberhasilan pendaftaran program MBA UoU. Selain itu, presisi SVM sebesar 96% dan naive bayes 90%, namun masih memenuhi target presisi yang ditetapkan oleh IEDU yaitu 85%. 
# Meskipun AUC Naive Bayes lebih tinggi daripada SVM (81.1% vs. 96.2%), kami lebih memilih SVM karena perbedaan AUC yang tidak signifikan dan SVM menunjukkan keunggulan yang lebih besar dalam hal akurasi dan presisi. Dan skor AUC 81,1% menurut kami sudah dapat meununjukan model dapat membedakan antara kelas positif dan negatif. Oleh karena itu, SVM dianggap sebagai model terbaik untuk konteks membantu IEDU memberikan saran yang lebih tepat kepada calon pendaftar program MBA UoU. 

#shiny
```{r}
#VERSI SIMPLE
library(shiny)
library(shinydashboard)
library(e1071)
library(shinyjs)

svm_reg_model = svm(LULUS ~ ., data = train_data[, c("LULUS", predictors)])

ui=fluidPage(
  titlePanel('IEDU Prediction Tool'),
  sidebarLayout(
    sidebarPanel(
      numericInput('Ranking_Uni_Asal','Ranking Uni Asal (1-5)', value=1),
      numericInput('IPK','IPK (0-4) boleh koma: ', value=0),
      textInput('RISET','RISET (Ya/Tidak):' ),
      numericInput("GRE", "Skor GRE", value = 0),
      numericInput("TOEFL", "Skor TOEFL", value = 0),
      numericInput("MOT_LETTER", "Skor Motivation Letter (1-5)", value = 0),
      numericInput("REKOM_LETTER", "Skor Rekomendasi Letter (1-5)", value = 0),
      actionButton('predict', 'predict')
    ), 
    mainPanel(
      textOutput('hasil')
    )
  )
)
server = function(input,output){
  observeEvent(input$predict, {
    predictions_IEDU= predict(svm_reg_model, newdata=data.frame(Ranking_Uni_Asal=input$Ranking_Uni_Asal, IPK=input$IPK, RISET=input$RISET, GRE=input$GRE, TOEFL=input$TOEFL, MOT_LETTER=input$MOT_LETTER, REKOM_LETTER=input$REKOM_LETTER))
    output$hasil= renderText({paste('Hasil Prediksi IEDU Anda adalah: ',predictions_IEDU)})
  })
}

shinyApp(ui, server)

```

```{r}
#VERSI BAGUS
library(shiny)
library(shinydashboard)
library(e1071)
library(shinyjs)

svm_reg_model = svm(LULUS ~ ., data = train_data[, c("LULUS", predictors)])

# Define UI
ui = dashboardPage(
  dashboardHeader(
    title = "IEDU Prediction Tool",
    titleWidth = 450, # Set width to accommodate subtitle
    tags$li(a(
      span(style = "color: #FFFFFF;", "Made By Wisely dan Denis"),
      class = "dropdown"
    ), class = "dropdown")
  ),
  
  dashboardSidebar(
    sidebarMenu(
      menuItem("Input Data Diri", tabName = "input", icon = icon("dashboard"))
    )
  ),
  
  dashboardBody(
    useShinyjs(), # Aktifkan shinyjs
    
 sidebarLayout(
    sidebarPanel(
      numericInput('Ranking_Uni_Asal','Ranking Uni Asal (1-5)', value=1),
      numericInput('IPK','IPK (0-4) boleh koma: ', value=0),
      textInput('RISET','RISET (Ya/Tidak):' ),
      numericInput("GRE", "Skor GRE", value = 0),
      numericInput("TOEFL", "Skor TOEFL", value = 0),
      numericInput("MOT_LETTER", "Skor Motivation Letter (1-5)", value = 0),
      numericInput("REKOM_LETTER", "Skor Rekomendasi Letter (1-5)", value = 0),
      actionButton('predict', 'predict')
    ), 
    mainPanel(
      textOutput('hasil')
    )
  )
))

server = function(input,output){
  observeEvent(input$predict, {
    predictions_IEDU= predict(svm_reg_model, newdata=data.frame(Ranking_Uni_Asal=input$Ranking_Uni_Asal, IPK=input$IPK, RISET=input$RISET, GRE=input$GRE, TOEFL=input$TOEFL, MOT_LETTER=input$MOT_LETTER, REKOM_LETTER=input$REKOM_LETTER))
    output$hasil= renderText({paste('Hasil Prediksi IEDU Anda adalah: ',predictions_IEDU)})
  })
}

shinyApp(ui, server)
```
