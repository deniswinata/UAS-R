---
title: "UAS Bahasa R"
author: "36220014-Wisely Yestin & 36220017 - Denis Winata "
---

#install packages
install.packages('dplyr')
install.packages('corrplot')
install.packages('nortest')
install.packages('moments')
install.packages('outliers')
install.packages('GGally')
install.packages('ggplot2')
install.packages('Metrics')
install.packages('caret')
install.packages('boot')
install.packages('performanceEstimation')
install.packages('pROC')
install.packages('psych')
install.packages('randomForest')
install.packages('rpart')
install.packages('e1071')
install.packages('gbm')
install.packages('class')
install.packages('nnet')
install.packages('xgboost')
install.packages('adabag')
install.packages('shiny')
install.packages('shinydashboard')
install.packages('shinyjs')

#import library
```{r}
library(dplyr)
library(corrplot)
library(nortest)
library(moments)
library(outliers)
library(GGally)
library(ggplot2)
library(Metrics)
library(caret)
library(boot)
library(performanceEstimation)
library(pROC)
library(psych)
```
#Load Dataset
```{r}
profiling=read.csv('profiling.csv', sep=';')
admisi=read.csv('admisi.csv', sep=';')

str(profiling)
str(admisi)

#View(profiling)
#View(admisi)
```
#eksplorasi data
```{r}
#cek apakah ada mising value?
anyNA(profiling)
anyNA(admisi)
```
#cek jumlah mising value
```{r}
missing_values_profiling = sapply(profiling, function(x) sum(is.na(x)))
missing_values_profiling
missing_values_admisi = sapply(admisi, function(x) sum(is.na(x)))
missing_values_admisi
```
#cek duplikat data
```{r}
anyDuplicated(profiling)
anyDuplicated(admisi)
#eksplor dataset
describe(admisi)
describe(profiling)
```
#data preprocessing

```{r}
profiling$IPK=gsub(",", ".", profiling$IPK)
profiling$IPK=as.numeric(profiling$IPK)
profiling$USIA=as.numeric(profiling$USIA)
profiling$Ranking_Uni_Asal=as.numeric(profiling$Ranking_Uni_Asal)

admisi$GRE=as.numeric(admisi$GRE)
admisi$TOEFL=as.numeric(admisi$TOEFL)
admisi$MOT_LETTER=gsub(",", ".", admisi$MOT_LETTER)
admisi$MOT_LETTER=as.numeric(admisi$MOT_LETTER)
admisi$REKOM_LETTER=gsub(",", ".", admisi$REKOM_LETTER)
admisi$REKOM_LETTER=as.numeric(admisi$REKOM_LETTER)

str(profiling)
str(admisi)
```

#Merge kedua dataset
```{r}
datauas=merge(profiling,admisi, by='ID')
datauas
str(datauas)
```
# Cek variasi keunikan data
```{r}
unique(datauas$JENIS_KEL)
unique(datauas$USIA)
unique(datauas$Ranking_Uni_Asal)#ada mising value
unique(datauas$RISET)#ada mising value tpi terisi kosong
unique(datauas$LULUS)#ada mising value
```

```{r}
mising_value_datauas=sapply(datauas, function(x) sum(is.na(x)))
mising_value_datauas
```

#handling missing value
```{r}
# Cek modus pada kolom missing value
modus_ranking = names(sort(table(datauas$Ranking_Uni_Asal), decreasing = TRUE)[1])
modus_ranking
modus_riset = names(sort(table(datauas$RISET), decreasing = TRUE)[1])
modus_riset
modus_lulus = names(sort(table(datauas$LULUS), decreasing = TRUE)[1])
modus_lulus

# Mengganti nilai NA dengan modus
datauas$LULUS[is.na(datauas$LULUS)] = modus_lulus
datauas$LULUS=as.factor(datauas$LULUS)
datauas$LULUS = factor(datauas$LULUS, levels = c(1, 0), labels = c('Lulus', 'Tidak Lulus'))
datauas$Ranking_Uni_Asal[is.na(datauas$Ranking_Uni_Asal)] = modus_ranking
datauas$Ranking_Uni_Asal=as.numeric(datauas$Ranking_Uni_Asal)
datauas$JENIS_KEL = as.factor(datauas$JENIS_KEL)

##mengisi kolom riset yg kosong namun tdk dianggep NA
# Membuat vektor dengan pilihan nilai "Ya" dan "Tidak"
choices = c("Ya", "Tidak")

# Mengidentifikasi indeks data yang kosong pada kolom "RISET"
kosong_index = which(datauas$RISET == "")

# Mendapatkan jumlah data yang kosong
jumlah_kosong = length(kosong_index)

# Menghasilkan nilai acak dan menggantikan nilai kosong
set.seed(123) 
datauas$RISET[kosong_index] <- sample(choices, jumlah_kosong, replace = TRUE)
datauas$RISET=as.factor(datauas$RISET)

# Mengisi nilai kosong dengan random
#datauas$RISET[is.na(datauas$RISET)] = sample(datauas$RISET[!is.na(datauas$RISET)], #sum(is.na(datauas$RISET)), replace = TRUE)

# Periksa apakah masih terdapat missing value
sum(is.na(datauas))
```

```{r}
summary(datauas)
describe(datauas)
```

# Handling Outlier
```{r}
#cek outlier dengan boxplot
boxplot(datauas$USIA)
boxplot(datauas$Ranking_Uni_Asal)
boxplot(datauas$IPK)#ad 2 outlier diatas
boxplot(datauas$GRE)
boxplot(datauas$TOEFL)
boxplot(datauas$MOT_LETTER)
boxplot(datauas$REKOM_LETTER)#ada 2 outlier dibawah
```

```{r}
# cek dan hapus outlier
# Loop untuk menampilkan boxplot satu per satu untuk variabel numerik
for (col in names(datauas)) {
  if (is.numeric(datauas[[col]])) {
    boxplot(datauas[[col]], main = col)
  }
}

# Menghapus Outliers pada IPK dan rekom letter
IQR_ipk = IQR(datauas$IPK)
up_outlier_ipk = quantile(datauas$IPK, 0.75) + 1.5 * IQR_ipk 

IQR_rekom = IQR(datauas$REKOM_LETTER)
low_outlier_rekom = quantile(datauas$REKOM_LETTER, 0.25) - 1.5 * IQR_rekom

datauas = subset(datauas, datauas$IPK <= up_outlier_ipk & datauas$REKOM_LETTER >= low_outlier_rekom)

# Mengecek apakah masih terdapat outliers
for (col in names(datauas)) {
  if (is.numeric(datauas[[col]])) {
    boxplot(datauas[[col]], main = col)
  }
}
```

#Normalisasi
```{r}
#cek normalisasi dengan test
#P value> 0,05 bagus
lillie.test(datauas$IPK)
lillie.test(datauas$Ranking_Uni_Asal)
lillie.test(datauas$GRE)
lillie.test(datauas$TOEFL)
lillie.test(datauas$MOT_LETTER)
lillie.test(datauas$REKOM_LETTER)

pearson.test(datauas$IPK)
pearson.test(datauas$Ranking_Uni_Asal)
pearson.test(datauas$GRE)
pearson.test(datauas$TOEFL)
pearson.test(datauas$MOT_LETTER)
pearson.test(datauas$REKOM_LETTER)

```

```{r}
#cek normalisasi dengan histogram
hist(datauas$USIA)
hist(datauas$Ranking_Uni_Asal)
hist(datauas$IPK)
hist(datauas$GRE)
hist(datauas$TOEFL)
hist(datauas$MOT_LETTER)
hist(datauas$REKOM_LETTER)
```

#Korelasi
```{r}
# Menghitung matriks korelasi antara kolom numerik
cor_matrix = cor(datauas[, sapply(datauas, is.numeric)])

# Plotting heatmap dengan ggplot2
ggplot(data = reshape2::melt(cor_matrix), aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, 
                       limit = c(-1,1), space = "Lab", name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
#feature usia dan id kurang penting
```

#Feature selection
```{r}
# Menentukan kontrol untuk model pembelajaran
control = trainControl(method="repeatedcv", number=15, repeats=5)

# Membuat model menggunakan train()
model = train(LULUS ~ ., data = datauas[, setdiff(names(datauas), "NAMA")], method = "lvq", preProcess = "scale", trControl = control)

# Menilai fitur yang penting
feature_selection = varImp(model, scale=FALSE)

# Plotting grafik tingkat pentingnya fitur
plot(feature_selection)
#feature usia,nama,id kurang penting
```

##modeling
```{r}
# Install dan load library yang dibutuhkan
#install.packages(c("randomForest", "rpart", "e1071", "gbm", "class", "nnet", "xgboost", "adabag"))
library(randomForest)
library(rpart)
library(e1071)
library(gbm)
library(class)
library(nnet)
library(xgboost)
library(adabag)

# Feature selection
predictors = c("RISET", "REKOM_LETTER", "MOT_LETTER", "Ranking_Uni_Asal", "GRE", "TOEFL", "IPK")

# Split train dan testing data
set.seed(123)  # Set seed for reproducibility
split_ratio <- 0.8 # 80% training, 20% testing
num_rows <- nrow(datauas)
train_indices <- sample(1:num_rows, size = round(split_ratio * num_rows))
train_data <- datauas[train_indices, ]
test_data <- datauas[-train_indices, ]
```

# Model Random Forest
```{r}
# Model Random Forest
rf_model = randomForest(factor(LULUS) ~ ., data = train_data[, c("LULUS", predictors)], ntree = 500, importance = TRUE)

# Model Prediction 
predictions_rf = predict(rf_model, newdata = test_data)

# Evaluate the model
conf_matrix = confusionMatrix(predictions_rf, test_data$LULUS)
accuracy_rf = conf_matrix$overall["Accuracy"]
precision_rf = conf_matrix$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Accuracy:", accuracy_rf))
print(paste("Precision:", precision_rf))
```

#Cross Validation Random Forest
```{r}
library(caret)

# Set seed for reproducibility
set.seed(123)

# Define cross-validation parameters
cv_folds = 5  # Number of folds for cross-validation

# Create cross-validated Random Forest model
rf_model_cv = train(factor(LULUS) ~ .,
                      data = train_data[, c("LULUS", predictors)],
                      method = "rf",
                      trControl = trainControl(method = "cv", number = cv_folds),
                      ntree = 500,
                      importance = TRUE)

# Print model summary
print(rf_model_cv)
```

# Curve ROC dan AUC Random Forest
```{r}
# Calculate ROC
roc_rf = roc(test_data$LULUS, as.numeric(predictions_rf))

# Display evaluation metrics
print(paste("Random Forest Accuracy:", accuracy_rf))
print(paste("Random Forest Precision:", precision_rf))

# Plot ROC curve for Random Forest
plot(roc_rf, col = "blue", main = "ROC Curve (Random Forest)", lwd = 2)
abline(h = seq(0, 1, 0.1), v = seq(0, 1, 0.1), col = "gray", lty = 3)

# Menghitung AUC
auc_rf = auc(roc_rf)
print(paste("Random Forest AUC:", auc_rf))
```

# Model Decision Tree
```{r}
library(rpart)

# Create and train the Decision Tree model
tree_model = rpart(LULUS ~ ., data = train_data[, c("LULUS", predictors)], method = "class")

# Model Prediction 
predictions_dt = predict(tree_model, newdata = test_data, type = "class")

# Evaluate the model
conf_matrix_dt = confusionMatrix(predictions_dt, test_data$LULUS)
accuracy_dt = conf_matrix_dt$overall["Accuracy"]
precision_dt = conf_matrix_dt$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Decision Tree Accuracy:", accuracy_dt))
print(paste("Decision Tree Precision:", precision_dt))
```
